\chapter{Requirements and Basic Design}\label{sec:design}

\section{Requirements}\label{subsec:requirements}

The following is the minimal set of user actions our Isabelle package shall
support:

\begin{enumerate}
\item Declare applicative functors to the theory context.
	Given a type constructor $f$, the functions $\pure_f$ and $\ap_f$, and
	proofs for the relevant functor laws, the functor is registered with the
	package such that it can be used in subsequent invocations of the
	proof method.
\item Prove lifted equations $a'[\vec{x}] = b'[\vec{x}]$, where $a'$ and $b'$
	are idiomatic expressions with free variables $\vec{x}$, using the base
	equation $\all{\vec{y}}{a[\vec{y}] = b[\vec{y}]}$.
	More precisely, if there is a subgoal stating the former, applying the
	proof methods transforms the goal state to the latter.
	The functor should either be detected automatically, or be specified
	by the user.
\end{enumerate}

The first requirement ensures that our package is reusable, while the second
is the core functionality.
However, usability is also a concern: In the realm of interactive theorem
proving, it is not sufficient to just verify formal objects---we are not
extending the logic, after all, but providing a shortcut following a certain
principle.
We must balance the clarity of the resulting proof document and the amount of
work that the user has to put into developing a proof.
The following features are possible extensions which may help in this regard:

\begin{enumerate}
\setcounter{enumi}{2}
\item\label{itm:feat-const}
	Declare lifted constants and other terms to the theory context.
	Generally speaking, if a term $t$ with free variables $v_i$ can be expressed
	as $\pure t' \ap v_1 \ap \cdots \ap v_n$ for some $t'$, then the
	corresponding equation can be registered.
	The proof methods rewrite with these equations at the beginning,
	such that the base equation will refer to $t'$.
	This way, the user does not have to transform everything into idiomatic
	format first.
\item\label{itm:feat-flex}
	More flexibility regarding the logical structure of the input proposition.
	This includes bound variables (quantified by $\forall$ or $\bigwedge$),
	complex subgoals with premises, and cases where the variables of the lifted
	equation have been substituted by some terms.
\item\label{itm:feat-tools}
	Related proof methods and attributes, for example for forward lifting
	of facts stating a base equation.
\item\label{itm:feat-debug}
	Inspection and tracing output.
	This is particular useful if something does not work as expected.
\item\label{itm:feat-xprops}
	Extend the notion of lifting beyond equations.
	It is possible to define lifting for other logical operators.
	For example, the cancellation law $a + b = a + c \longrightarrow b = c$
	consists of two equations, joined by implication.
	We can interpret it in different domains, e.g., for integers and for
	streams of integers with element-wise addition.
	In this example, the law is true for both interpretations.
	We are not able to handle such propositions with a method just for
	equations.
\end{enumerate}

The current version at the time writing supports \ref{itm:feat-const} and
\ref{itm:feat-flex}, as well as the forward lifting described in~\ref{itm:feat-tools}.
In the remainder of this section, we will explain the design decisions we
have made in order to fulfill the requirements.
Furthermore, the registration infrastructure and the basic proof approach are
explained.


\section{Choice of Embedding}\label{subsec:embedding}

The basic principle of proof composition in Isabelle is resolution with a proven
theorem, using it as a rule of inference.
Here we argue that it is not possible to prove lifting as a single theorem, and
then we discuss potential remedies.
We are interested in applicative functors on the type level, where application
is based on the standard function space.
Therefore, each idiom comes with a type family which is indexed by a
distinguished type variable, and the related functions and laws are polymorphic
in this index.
This is the natural form of idioms in the HOL libraries; all examples mentioned
in Section~\ref{subsec:motivation} are parametric datatypes.
The proof method should work directly with equations involving these.
Regardless of the mechanism of proof construction, it needs a type constructor
as a parameter.
This concept is foreign to the type system of Pure and HOL---%
we already referred to the fact that type constructors are fixed.
Another issue is the lack of polymorphism in the inner logic:
We cannot have, say, a schematic variable \textit{?pure} and use it with
different types within the same proposition or proof.

One solution is to define a custom logic, including a term language, axioms
and meta theorems, and formalize it using the available specification tools.
In our case, the language is that of idiomatic expressions,%
\footnote{Base equations can be interpreted as expressions in the identity idiom.}
the axioms describe an equality judgment which is compatible with the
applicative functor laws, and lifting of equations is a theorem.
This is a \emph{deep embedding} of the logic~\cite{wildmoser04}.
With its tools for algebraic datatypes and recursive functions, reasoning about
such an embedding is quite manageable in HOL.
However, we want to prove propositions involving objects of HOL itself, not just
their encodings in the embedded language.
Some machinery, known as reflection, needs to perform the encoding and transfer
back results.
It must be implemented necessarily outside of the logic, but can be generic.
Chaieb and Nipkow have implemented a proof procedure using a deep embedding and
reflection in Isabelle~\cite{chaieb05}.
They point out that their approach also functions as a verification of the
proof procedure, is portable and has smaller proofs than those obtained by
automating inference rules.
Their reflection system does not support polymorphism to the extent we need,
though.

The package for nonfree datatypes~\cite{schropp13} is deeply embedded as well.
Its constructions must work with arbitrary types.
In the underlying framework, Schropp~\cite{schropp12} proposed the use of a
``pseudo-universe'', a sum type combining all relevant types.
The meta-theory of the package carries a type parameter which is instantiated
with a suitable pseudo-universe for every construction.
It may be possible to use the same approach for idiomatic expressions, since the
number of types occuring in an idiomatic expression is finite.
This number can be linear in the size of the expression, though, which bloats
the intermediate terms during reflection.
A bigger problem is the axiomatization of idioms.
For instance, the identity law would refer to a function of type $\alpha \funT \alpha$
for each type $\alpha$ in the pseudo-universe.
Thus, the universe needs to be closed under function types.
It is not clear to the author how this could be modelled.

A different approach, which is the one we will take, is a \emph{shallow embedding}.
The formulas (here, idiomatic terms) are expressed directly in the language of HOL.
Due to aforementioned restrictions, meta-theorectical results must be provided
in specialized form for each case.
We use the powerful ML interface of Isabelle to program the proof construction,
composing inferences according to the structure of the input equation.
The handling of polymorphism is simplified, as we have full control over
term and theorem instantiations.
The system still verifies the soundness of the synthesized proofs.
On the other hand, one has to assert externally that the construction algorithm
itself is correct, i.e., complete.
The main part of this report therefore justifies these algorithms.


\section{Proof Strategy}\label{subsec:proof-strategy}

The ML code of the package can be considered in two parts.
One is concerned with registration of idioms and access to the recorded
information, the other provides the actual proof methods.
We start with a summary of the former component.
It does not only store the idioms declared with the \textbf{applicative}
command (see Section~\ref{subsec:user-interface}), but also deals with the high
degree of polymorphism.
First, we need to represent the concept of an idiom.
Instead of a plain type constructor we use type schemes $f[\tvar{a}]$, which
are normal HOL types with (in this case) one distinguished type variable
$\tvar{a}$.
This variable has to be tracked externally in ML because of the lack of
type quantifiers in the type system.
The lifted type of $\alpha$ is then obtained by substitution of $\tvar{a}$ by
$\alpha$ in $f[\tvar{a}]$.
The functions $\pure_f$ and $\ap_f$ thus have types
$\tvar{a} \funT f[\tvar{a}]$ and $f[\tvar{a} \funT \tvar{b}] \funT f[\tvar{a}] \funT f[\tvar{b}]$,
respectively.
We allow additional type variables in functor signatures, which therefore
represent families of functors.
These variables are always instantiated with the same types throughout a proof.
This is useful for idioms based on sum types $\alpha + \beta$, for instance.
As a further refinement, all type variables may be constrained by a sort.
Sorts in Pure are type classes~\cite{implementation-ref}.
The sort of the distinguished variable in $f$ must be compatible with the
function type constructor.

These logical entities together form the signature of the idiom $f$.
We define functions which compose and destruct types and terms related to $f$.
One problem is to identify terms of the form $\pure \_$ and $\_ \ap \_$ in
the first place.
We do not want to restrict the term structure of the functor ``constants'',
since some useful predefined concepts in the HOL libraries are abbreviations of
compound terms.
Isabelle's higher-order matching appears to be a proper solution in practice,
using $\pure v$ (or $v_1 \ap v_2$) with new variables $v$ ($v_1$, $v_2$) as the
pattern.

The remaining code uses these functions to provide several layers of
conversions and tactics.
A wrapper tactic prepares the subgoal to solve.
This includes dealing with universal quantifiers and local premises.
Then, we rewrite the subgoal using the declared rules for lifted constants.
Only those related to $f$ are used, the reason being that overeager, unwanted
unfolding may be difficult to reverse.
The result of this preparation is a subgoal which is a simple equation of two
idiomatic expressions.
We provide two variants of the basic lifting step.
They have in common that both expressions are transformed into \emph{canonical form}:
\[ \pure{g} \ap s_1 \ap \cdots \ap s_m = \pure{h} \ap t_1 \ap \cdots \ap t_n, \]
We apply appropriate congruence rules until the subgoal is reduced to $g = h$.
If either $m \ne n$ or $s_i \ne t_i$ for some $i$ (as terms modulo
$\alpha\beta\eta$-conversion), the proof method fails.
Since $g$ and $h$ are at least $n$-ary functions, we can further apply
extensionality, and obtain the subgoal
\[ \All{x_1 \dots x_n}{g x_1 \cdots x_n = h x_1 \cdots x_n}. \]
This is the transformed proof state presented to the user.

Hinze's Normal Form Lemma~\cite[7]{hinze10} asserts the existence of a normal
form for idiomatic expressions where each variable occurs only once.
As it turns out, we can compute it for arbitrary expressions.
This normal form is a canonical form.
Therefore, the first variant simply replaces both sides of the equation with
the normal form.
The details of the normalization algorithm are described in
Section~\ref{sec:normal-form}.
There we will also show that the transformed equation is indeed the base form
of the original equation.
The other implementation is a superset of the normal form approach.
Instead of using the unique normal form, we construct canonical forms
explicitly such that the condition $\vec s = \vec t$ is satisfied.
The idiom under consideration limits the set of equivalent canonical forms,
though.
The construction is related to bracket abstraction of lambda terms---%
we add combinators to the term in order to separate the lifted part from
the variables.
This is further explained in Section~\ref{sec:combinators}.
