\section{Introduction}\label{sec:introduction}

\subsection{Motivation}\label{subsec:motivation} % TODO change?

Interactive theorem provers emphasize the human aspect of mathematical work.
Rather than relying on fully automatic proof search, the user guides
the process with their own understanding~\cite{harrison07}.
This requires a sufficiently expressive interface with features beyond plain
logical calculus.
In particular, there exists a demand for automation and abstraction of
patterns~\cite{bourke12}.
It is thus common to extend proving environments with (sometimes
domain-specific) tools.

In this report we present a particular variant of lifting we have implemented
for the Isabelle/HOL proof assistant~\cite{npw02}.
The term ``lifting'' is used in different contexts, often informally.
It vaguely refers to the transfer of mathematical objects between domains,
while preserving a certain relationship.
A concrete example are lifts of paths in topology. % TODO cite
There is also an existing Isabelle package~\cite{huffman13}, which lifts
definitions to quotient types.
Here we consider a slightly different meaning of lifting:
The transfer of operations and their properties to generic structures.
Since HOL is a typed logic, it is natural to represent these structures as
parametric types.
Let us look at a simple example.

\begin{example}\label{exmp:set-intro}
For each type $\alpha$ there is a corresponding type $\alpha\,\mathit{set}$
of sets with elements from $\alpha$.
Addition $(+)$ is a binary operator defined on natural numbers, amongst others.
How could addition of sets of natural numbers be defined, such that some
relation to $+$ remains?
The canonical way to combine two sets into a set of pairs is the cartesian
product.
Therefore, we define
\begin{equation}\label{eq:set-plus-exp}
	X \oplus Y = \set{x + y}{x \in X,\, y \in Y}.
\end{equation}
We interpret $\oplus$ as the lifting of $+$ to sets.
Note that similar definitions are possible for other operators like
multiplication, and also other element types such as real numbers.
A property of addition is associativity,
\begin{equation}\label{eq:plus-assoc}
	\all{x y z}{(x + y) + z = x + (y + z)}.
\end{equation}
It can be translated to sets of natural numbers,
\begin{equation}\label{eq:set-plus-assoc}
	\all{X Y Z}{(X \oplus Y) \oplus Z = X \oplus (Y \oplus Z)},
\end{equation}
where it holds as well, as one can check with a slightly laborious proof.
The two sides of the latter equation can be regarded as functions with three
arguments.
They are the lifted counterparts of the former equation.
\end{example}

Hinze~\cite{hinze10} came across similar patterns and proceeded to investigate
the conditions under which lifted equations are preserved.
He noticed that lifting can be defined in an intuitive fashion if the target
structure is an applicative functor~\cite{mcbride08}.
These come with two constants, usually denoted $\pure$ and $\ap$ (``ap''),
which lift a single object and the notion of function application, respectively.
Applicative functors must also satisfy some properties, which we restate in
Section~\ref{subsec:applicative}.

Every monad is an applicative functor.
Monads are a common mechanism for handling effects in functional
programming~\cite{wadler95}.
Such being the case, they are also useful for modelling in the context of
verification.
The difference between monads and applicative functors is that the latter
do not allow sub-computations to depend on previous results.
From there we can borrow quite a few examples of applicative functors:
Sum types with one variable type (known as \textsf{Either} in Haskell),
the reader monad or environment functor, the exception/backtracking list
monad~\cite{wadler85}, the state monad, and parser combinators.
Hinze originally worked on streams (infinite lists) and infinite
trees~\cite{hinze08,hinze09}.
We conclude that there are indeed relevant applicative functors, which supports
the argument that this kind of lifting is a useful abstraction.

\addtocounter{example}{-1}
\begin{example}[continued]
Back to sets, we obtain an applicative functor if $\pure$ is the singleton set
constructor $x \mapsto \{x\}$;
$F \ap X$ takes a set of functions $F$ and a set of arguments $X$
with compatible type, applying each function to each argument:
\begin{equation}\label{eq:set-ap}
	F \ap X = \set{f x}{f \in F,\, x \in X}.
\end{equation}
Now we can express lifted addition directly in terms of the base operation:%
\footnote{As customary in HOL, we treat binary operators as curried functions.}
\begin{equation}\label{eq:set-plus}
	X \oplus Y = \pure{(+)} \ap X \ap Y.
\end{equation}
(The operator $\ap$ is left-associative.)
This definition is equivalent to the previous one \eqref{eq:set-plus-exp},
but not specific to sets anymore.
\end{example}

As we have seen earlier, lifting can be generalized to equations.
One of Hinze's results is that a fundamental relationship exists between the
associative properties \eqref{eq:plus-assoc} and~\eqref{eq:set-plus-assoc}%
---the lifted form can be proven for all applicative functors, not just
$\mathit{set}$.
Moreover, this is possible for other equations as well, but not all equations
can be lifted in all functors.
Stronger conditions are required if the list of quantified variables is
different for each side of the equation.
(The left-to-right order is relevant, but not the nesting within the terms.)
These conditions must basically ensure that the functor does not add ``too many
effects'' which go beyond the simple embedding of a base type.
Such effects may be evoked if a variable takes an impure value, i.e., a value
which is not equal to $\pure x$ for any $x$.
Hinze showed that sufficient conditions can be expressed in terms of combinators
as known from combinatory logic.

These findings justify direct proofs of lifted equations.
It desirable to enable such reasoning in a proof assistant.

\begin{example}\label{exmp:set-counterexmp}
We try to lift the fact that zero is a left absorbing element for
multiplication of natural numbers, $\all{x \oftype \mathit{nat}}{0 \cdot x = 0}$,
to sets.
Note that the variable $x$ occurs only on the left.
But the lifted equation does not hold: If $x$, now generalized to
$\mathit{nat}\,\mathit{set}$, is instantiated with the empty set, then
\[ \pure{(\cdot)} \ap \pure 0 \ap \{\} = \{\} \ne \pure 0. \]
Here the effect of $\{\}$ is that it cancels out everything else if it occurs
somewhere in an lifted expression.
This makes it impossible to lift any equation with a variable occuring only on
one side to $\mathit{set}$.
We will see that other functors permit this lifting.
\end{example}


\subsection{Contributions and Overview}\label{subsec:contrib-overview}

Our primary goal is to provide an Isabelle/HOL proof method which reduces
lifted equations to their base form.
The method can be instantiated for arbitrary applicative functors.
Then the user is able to prove the lifted equations directly without having to
invent a specific proof strategy, or even simulate the approach taken here.
Apart from the theoretical appeal of the method, the resulting proof text is
usually more concise, due to the higher level of abstraction.
Together with some infrastructure, the proof method forms a basic package
for reasoning with applicative functors.

Hinze's work is the basis for the package.
He has identified the suitability of applicative functors and shown
necessary conditions for lifting of equations.
However, we needed to adapt the details to the HOL environment in order to
construct actual proofs.
This construction is directly programmed on top of Isabelle's ML interface.
We have therefore derived the correctness and some other properties of our
approach formally using a simplified calculus.
Moreover, we have further extended the idea of combinators as building blocks
for lifting, generalizing Hinze's model conditions.
Consequently, the package supports several combinator sets which functors may
exhibit, each capable of lifting different sets of equations.
A particular motivation for our package are arithmetic operations on streams
and infinite trees.
We have proven some of their properties as a usage example.

The remainder of this report is organized as follows:
The present section concludes with some background information on Isabelle/HOL,
applicative functors, and a concrete definition of lifting.
Section~\ref{sec:design} describes the design considerations, discusses the
choice of embedding, and provides a high-level overview of the proof method.
In the next two sections, we present the details of the two strategies we
have implemented:
Section~\ref{sec:normal-form} shows an implementation of the normal form of
lifted expressions;
Section~\ref{sec:combinators} is concerned with combinators and the application
of bracket abstraction to applicative terms.
\todo\ application example, related work, conclusion


\subsection{Proving with Isabelle/HOL}\label{subsec:isabelle}

Isabelle was originally designed as a framework for interactive theorem
proving, without being restricted to a specific logical system~\cite{paulson90}.
However, one chooses a particular object-logic in order to construct a theory
and prove theorems.
In this paper, we focus on the Isabelle/HOL object-logic~\cite{npw02}.
It implements the higher-order logic which was used in the HOL~system,
another proving environment~\cite{gordon93}.
Isabelle/HOL (or HOL from here~on) is arguably the most popular object-logic
of Isabelle, as it comes with an extensive library of readily formalized
mathematics.
It also supports modelling of functional programs by means of datatypes and
recursive functions, making it suitable for verification tasks. % TODO cite?

The basis of HOL is a slightly extended variant of simply-typed lambda calculus.
Therefore, every object (and every term representing such an object) has a
certain type attached to it.
We use lower-case greek letters $\alpha$, $\beta$, $\gamma$ as meta-variables
for types.
The language of types consists of base types, type variables, and compound
types.
Base types are represented by their name and include fundamental types like
the booleans $\mathit{bool}$ and the natural numbers $\mathit{nat}$.
Type variables stand for an arbitrary types.
In Isabelle syntax, they are distinguished by a prefixed `$'$', e.g.
$\tvar{a}$, $\tvar{b}$, $\tvar{c}$.
The polymorphism in HOL is quite restricted, though, because higher-ranked
types cannot be expressed:
There is no explicit quantifier on the type level.
This rules out functions which take a polymorphic function as an argument and
apply it to values of different types.
Compound types are built up of a type constructor and a list of types.
The type constructor determines the number of argument types.
For example, the unary type constructor $\mathit{set}$ denotes sets with
elements of a certain type.
The argument is written on the left as in $\mathit{nat\,set}$, the type of
sets of natural numbers.
Multiple types are written in parentheses: $(\alpha, \beta) \mathit{fun}$.
$\mathit{fun}$ is the special type constructor for (total) functions from
$\alpha$ to $\beta$.
More commonly, the infix operator $\funT$ is used.
It is right-associative, i.e. $\alpha \funT \beta \funT \gamma$ is notation for
$(\alpha, (\beta, \gamma) \mathit{fun}) \mathit{fun}$.
Note that type constructors are different from types and must always be
concrete.
In particular, it is not possible to use a variable in place of a type
constructor!

Terms follow the standard rules of lambda calculus.
Atomic terms are constants and variables.
Application of a function $f$ to an argument $x$ is written $f\,x$.
Functions with multiple arguments are commonly curried in HOL;
we can drop parentheses accordingly: $f\,x\,y$ is the same as $(f\,x)\,y$.
Abstraction of a term $t$ over the variable $x$ is written $\abs{x}{t}$.
Terms must be well-typed, of course.
The types of variables and polymorphic constants can usually be omitted, since
they are inferred automatically.
Explicit type constraints are denoted by $t \oftype \alpha$ and may occur
anywhere in a term.
While all terms are represented internally roughly as shown above, Isabelle
comes with extensible notation support.

\begin{example}\label{exmp:hol-terms}
We already introduced the type $\mathit{nat}$.
Number literals can be used directly.
Common arithmetic operators are available, like%
\footnote{These functions actually have a more generic type (they are
overloaded). We will look at this later on.}
$\mathit{plus} \oftype \mathit{nat} \funT \mathit{nat} \funT \mathit{nat}$.
We can also use infix operators:
\[ \abs{(x \oftype \mathit{nat})\,y}{1 + x * y} \]
is a function which multiplies two natural numbers and adds one to the result.
Another important type family are sets.
They can be specified as finite collections $\{\}$, $\{a, b, c\}$ etc., and
by using set comprehension:
Let $P$ be a predicate $\alpha \funT \mathit{bool}$.
Then $\{x.\; P x\}$ is the set of those values $x \oftype \alpha$ such that
$P x$ is true, and $\set{f x}{x.\; P x}$ is the image of that set under $f$.

Logical formulas are centered around truth values.
Thus, the usual connectives like conjunction $\land$ and implication $\imp$
operate on type $\mathit{bool}$.
Quantifiers work just as expected: The term
\[ \all{(x \oftype \mathit{nat})\,y}{x + y = y + x} \]
states that addition of natural numbers is commutative.
Note that $=$ is just another operator of polymorphic type
$\tvar{a} \funT \tvar{a} \funT \mathit{bool}$.
Internally, quantifiers are represented as constants applied to lambda
abstractions, which handle the variable binding.
\end{example}

In order to support different object-logics, Isabelle contains an immediate
layer, the meta-logic Pure (see e.g. \cite[Chapter~2]{implementation-ref}).
It is an ``intuitionistic fragment of higher-order logic''~\cite[27]{isar-ref}.
Pure has two main uses within the Isabelle framework: representation and
manipulation of deduction rules, and goal states.
While our user interface is intended to be used with HOL, the underlying
theorems are always represented as propositions of Pure.
Therefore it plays an ancillary role in our tool.
The following operators are separate from those of HOL:
meta-quantification $\bigwedge$ instead of the universal quantifier $\forall$,
and meta-equality $\equiv$ instead of $=$.
Each of these are logically equivalent, though.
In particular, the generic rewriting and simplification tools work with $\equiv$.
As an example of Pure, consider the symmetry axiom for $\equiv$ in traditional
rule format,
\[ \frac{\Gamma \vdash x \equiv y}{\Gamma \vdash y \equiv x}. \]
Deduction in Isabelle handles the context $\Gamma$ automatically, and
therefore does not have to be stated in the corresponding proposition.
The dependency of the conclusion on the hypothesis translates to
meta-implication;
the outermost meta-quantified variables (and all type variables) % FIXME
are turned into schematic variables, which are free variables distinguished by
the prefix $\svar{}$.
Thus, the symmetry axiom appears as the theorem
\[ \mathtt{symmetric}:\quad \svar{x} \equiv \svar{y} \Imp \svar{y} \equiv \svar{x}. \]
Schematic (type) variables are eligible for instantiation by some core
functions. % FIXME

Isabelle is an LCF-style prover, i.e., proofs are composed by invoking
trusted, primitive inferences programmed in the implementation language
SML, at least on the lowest level.
For instance, the symmetry axiom is available in combination with modus ponens
as the function \verb|Thm.symmetric|, which takes a theorem $x \equiv y$ and
returns a new theorem $y \equiv x$.
The function is part of the large SML interface of Isabelle, which not only
constitutes its implementation, but can also be used for new tools.

In contemporary use of Isabelle, user input to the system is expressed in
the Isar language~\cite{wenzel99,wenzel02,isar-ref}.
It aims to encode proofs in a way that is formal, i.e. has precise semantics,
but still resembles informal patterns of reasoning.
The basic organization unit in Isar is a theory.
The body of a theory consists of a sequence of commands, which consecutively
augment the logical context by declarations of various kinds.
Other theories may be imported in the beginning, leading to a acyclic graph
of theory dependencies.
The set of data stored within a theory can be extended through the programming
interface.
This is relevant to us, because it allows us to register applicative
functors in the theory context.

Commands constitute the so-called outer syntax of Isar.
Terms and types occuring within them are parsed separately, according to the
inner syntax.
In certain cases, a command may put the theory state into proof mode.
After the proof is finished, the associated goal becomes a fact, which can be
further handled by some associated code.
The important \textbf{lemma} family of commands works this way, for example.
New commands are frequently introduced for specifications.
For example, algebraic datatypes can be defined with the \textbf{datatype} command.
Finally, there are other extensible syntactical categories which are commonly
used in Isar:
Proof methods denote (possibly parameterized) operations on the goal state
within a regular Isar proof.
These operations are provided by arbitrary code and thus can be arbitrarily
complex.
Attributes invoke further processing steps on already proven facts, either
transforming them or causing additional declarations to the context.


\subsection{Applicative Functors and Lifting}\label{subsec:applicative}

Applicative functors were introduced by McBride and Paterson~\cite{mcbride08}
in order to abstract a recurring theme they observed in the programming language
Haskell.
In fact, their findings already included some examples of lifting.
They defined an applicative functor as a unary type constructor $f$ with
associated constants
\begin{align*}
	\pure_f &\oftype \alpha \funT \alpha f, \\
	(\ap_f) &\oftype (\alpha \funT \beta) f \funT \alpha f \funT \beta f.
\end{align*}
We omit the subscripts if the functor is clear from the context.
Moreover, the following laws must be satisfied:
\begin{align*}
	\tag{identity} \pure{\mathit{id}} \ap u &= u \\
	\tag{composition} \pure{(\cdot)} \ap u \ap v \ap w &= u \ap (v \ap w) \\
	\tag{homomorphism} \pure{f} \ap \pure x &= \pure{(f x)} \\
	\tag{interchange} u \ap \pure{x} &= \pure{(\abs{f}{f x})} \ap u
\end{align*}
We have already seen how the two constants can be used to build terms.
McBride and Paterson coined the term ``idiom'' to refer to a particular
interpretation of such terms.
In line with Hinze, we will use ``applicative functor'' and ``idiom''
interchangeably.

The identity type constructor defined by $\alpha\,\mathit{id} = \alpha$ is a
trivial applicative functor for $\pure{x} = x$, $f \ap x = f x$.
We can take any abstraction-free term $t$ and replace each constant $c$ by
$\pure{c}$, and each instance of function application $f x$ by $f \ap x$.
The rewritten term is equivalent to $t$ when interpreted in the identity idiom.
By choosing a different idiom, we obtain a different interpretation of the same
term structure.
In fact, this is exactly how we define the lifting of $t$.
However, the terms we are interested in can also contain variables:
Equations such as~\eqref{eq:plus-assoc} are universally quantified.
For the purpose of lifting, we ignore quantifiers and treat their variables
as free.
Like in Example~\ref{exmp:set-intro}, the variables of lifted equation should
range over the lifted type.
Note that these can take impure values.
A term consisting only of $\pure$ and $\ap$ applications and free variables is
then called an \emph{idiomatic expression}.

Every idiom is a functor, of course, and thus can be mapped over.
One obtains an equivalent formalization of idioms:
\begin{alignat*}{2}
	\mathit{map}_f &\oftype (\alpha \funT \beta) \funT \alpha f \funT \beta f, &\qquad
		\operatorname{\mathit{map}}_f\,g\,x &= \pure g \ap x, \\
	\mathit{unit}_f &\oftype () f, &\qquad \mathit{unit}_f &= \pure{()}, \\
	(\star_f) &\oftype \alpha f \funT \beta f \funT (\alpha, \beta) f, &\qquad
		x \star_f y &= \pure{(\abs{x y}{(x,y)})} \ap x \ap y.
\end{alignat*}
Some of Hinze's proofs make use of these definitions.
Dealing with product types can be a bit cumbersome in HOL, though.
The curried interface therefore seems to be a better choice, and we will
focus solely on that.
